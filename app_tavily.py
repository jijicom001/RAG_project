from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import SQLChatMessageHistory
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain.agents import create_openai_tools_agent, AgentExecutor  
from langchain.tools.retriever import create_retriever_tool           
from langchain_community.tools.tavily_search import TavilySearchResults  
from qdrant_client import QdrantClient
from langchain_qdrant import QdrantVectorStore
from dotenv import dotenv_values
from sqlalchemy import create_engine
from datetime import datetime
import os
import uvicorn

config = dotenv_values(".env")
os.environ['TAVILY_API_KEY'] = config.get("TAVILY_API_KEY")

llm = AzureChatOpenAI(
    azure_endpoint=config.get("AZURE_OPENAI_ENDPOINT"),
    azure_deployment=config.get("AZURE_OPENAI_DEPLOYMENT_NAME"),
    api_key=config.get("AZURE_OPENAI_KEY"),
    openai_api_version=config.get("AZURE_OPENAI_API_VERSION"),
    temperature=0.7,
    top_p=0.92,
)

embedding_llm = AzureOpenAIEmbeddings(
    azure_endpoint=config.get("AZURE_OPENAI_ENDPOINT"),
    azure_deployment=config.get("AZURE_OPENAI_DEPLOYMENT_NAME_EMBEDDING"),
    api_key=config.get("AZURE_OPENAI_KEY"),
    openai_api_version=config.get("AZURE_OPENAI_API_VERSION"),
)

client = QdrantClient(url=config.get("QDRANT_URL"), api_key=config.get("QDRANT_API_KEY"))
qdrant = QdrantVectorStore(
    client=client,
    collection_name="Mother_HandBook",
    embedding=embedding_llm
)

retriever_tool = create_retriever_tool(
    qdrant.as_retriever(search_kwargs={"k": 5, "score_threshold": 0.5}),
    "breastfeeding_assistant",
    "ç•¶å•é¡Œèˆ‡æ¯ä¹³å“ºè‚²ã€è‚²å…’ç›¸é—œæ™‚ï¼Œè«‹ä½¿ç”¨é€™å€‹å·¥å…·ä¾†å›ç­”ã€‚"
)

tavily_tool = TavilySearchResults(max_results=3, recent_only=True)

tools = [retriever_tool, tavily_tool]

current_date = datetime.now().strftime("%Y-%m-%d")

prompt = ChatPromptTemplate.from_messages([
    ("system", f"""
    ä½ æ˜¯ä¸€ä½ç†±æƒ…ä¸”å‹å–„çš„æ¯ä¹³å“ºè‚²åŠ©æ‰‹ï¼Œå¹«åŠ©ä½¿ç”¨è€…è§£æ±ºæ¯ä¹³é¤µé¤Šå•é¡Œã€‚
    ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
    - breastfeeding_assistant: æŸ¥è©¢æ¯ä¹³å“ºè‚²å’Œè‚²å…’ç›¸é—œçŸ¥è­˜
    - tavily_search_results_json: æŸ¥è©¢å³æ™‚è³‡è¨Šï¼Œä¾‹å¦‚æ–°èã€é†«é™¢ã€å¤©æ°£ç­‰

    ä»Šå¤©æ—¥æœŸæ˜¯ {current_date}ã€‚
    å¦‚æœæ˜¯æ¯ä¹³å“ºè‚²å•é¡Œï¼Œè«‹å„ªå…ˆä½¿ç”¨ breastfeeding_assistantã€‚
    å¦‚æœå•é¡Œæ¶‰åŠå³æ™‚è³‡è¨Šï¼ˆä¾‹å¦‚æ–°èã€å¤©æ°£ï¼‰ï¼Œè«‹ä½¿ç”¨ tavily_search_results_jsonã€‚
    """),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
    MessagesPlaceholder("agent_scratchpad")
])

def get_session_history(session_id):
    engine = create_engine("sqlite:///../tavily.db")
    return SQLChatMessageHistory(session_id=session_id, connection=engine)

app = FastAPI()

class ChatRequest(BaseModel):
    message: str
    session_id: str = "anonymous_user"

@app.post("/query")
async def chat(request: ChatRequest):
    try:
        session_id = request.session_id
        user_input = request.message

        print(f"ğŸ” æ¥æ”¶åˆ°è«‹æ±‚: session_id={session_id}, message={user_input}")

        session_history = get_session_history(session_id)
        chat_history = [{"role": "user", "content": msg.content} if msg.type == "human"
                        else {"role": "ai", "content": msg.content}
                        for msg in session_history.messages]

        agent = create_openai_tools_agent(llm, tools, prompt)

        agent_executor = AgentExecutor(
            agent=agent,
            tools=tools,
            verbose=True
        )

        search_results = tavily_tool.run(user_input)

        result = agent_executor.invoke({
            "input": user_input,
            "chat_history": chat_history,
            "search_results": search_results,
        }, config={"configurable": {"session_id": session_id}})

        session_history.add_user_message(user_input)
        session_history.add_ai_message(result["output"])

        return {"answer": result["output"]}

    except Exception as e:
        import traceback
        error_trace = traceback.format_exc()
        print(f"âš ï¸ FastAPI å…§éƒ¨éŒ¯èª¤: {error_trace}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
